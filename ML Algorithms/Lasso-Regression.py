# -*- coding: utf-8 -*-
"""LassoRegressionHW4.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1pfnP2XOjZtzcbBCX7H967Jq4owPc3V1T
"""

from pandas.io.parsers.readers import read_table
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt



df_train = pd.read_table("crime-train.txt").values
df_test = pd.read_table("crime-test.txt").values




x_train = df_train[:, [3, 12, 39, 45, 66]]
y_train = df_train[:,0]
x_test = df_test[:,1:]
y_test = df_test[:,0]

def soft_threshold(r, l):
  if r < -l /2:
    return r + l / 2
  elif r > l /2:
    return r + l / 2
  else:
    return 0

def lasso_coordinate_descent(x, y, lam, w_init, conv_threshold=1e-6, max_iter=1000):

    w = w_init
    p, n = x.shape
    x = x / (np.linalg.norm(x,axis = 0))
    
    for i in range(max_iter):

        w_old = w.copy()

        for j in range(n):
      
            xj = x[:,j]
            yp = x.dot(w)
            r = xj.dot(y - yp + xj*w[j])
            w[j] = soft_threshold(r, lam) / xj.dot(xj)
            
            
        if np.abs(w - w_old).max() < conv_threshold:
                break

    return w.flatten()


# Define lambda values
lambdas = np.logspace(0,4,300)/10

w = np.random.rand(x_train[0].size)


# Run coordinate descent for each lambda value
coefficients = []
train_errors = []
test_errors = []


for lam in lambdas:
    w = lasso_coordinate_descent(x_train, y_train, lam, w)
    coefficients.append(w)

# Convert coefficients to numpy array
coefficients = np.array(coefficients)

plt.plot(lambdas, coefficients)
plt.xscale('log')
plt.show()

from pandas.io.parsers.readers import read_table
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt


df_train = pd.read_table("crime-train.txt").values
df_test = pd.read_table("crime-test.txt").values

x_train = df_train[:,1:]
y_train = df_train[:,0]
x_test = df_test[:,1:]
y_test = df_test[:,0]

def soft_threshold(r, l):
    if r < -l:
        return r + l 
    elif r > l:
        return r - l 
    else:
        return 0

def lasso_coordinate_descent(x, y, lam, w_init, conv_threshold=1e-6, max_iter=1000):

    w = w_init
    p, n = x.shape
    x = x / (np.linalg.norm(x,axis = 0))
    
    for i in range(max_iter):

        w_old = w.copy()

        for j in range(n):
      
            xj = x[:,j]
            yp = x.dot(w)
            r = xj.dot(y - yp + xj*w[j])
            w[j] = soft_threshold(r, lam) / xj.dot(xj)
            
            
        if np.abs(w - w_old).max() < conv_threshold:
                break

    return w.flatten()

# Define lambda values
lambdas = np.logspace(0,4,300)/10

w = np.random.rand(x_train[0].size)

# Run coordinate descent for each lambda value
coefficients = []
trainMSE = []
testMSE = []
nonzero_coeffs = []

for lam in lambdas:
    w = lasso_coordinate_descent(x_train, y_train, lam, w)
    coefficients.append(w)
    train_MSE = np.mean((y_train - x_train.dot(w)) ** 2)
    trainMSE.append(train_MSE)
    test_MSE = np.mean((y_train - x_train.dot(w)) ** 2)
    testMSE.append(test_MSE)
    nonzero_coeffs.append(np.count_nonzero(w))


plt.figure()
plt.plot(np.log10(lambdas), trainMSE)
plt.show()


plt.figure()
plt.plot(np.log10(lambdas), testMSE)
plt.show()


plt.figure()
plt.plot(lambdas, nonzero_coeffs)
plt.show()



